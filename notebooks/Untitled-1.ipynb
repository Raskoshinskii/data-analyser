{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analyser Workflow Tutorial\n",
    "\n",
    "This notebook demonstrates how the workflow system in `src/agent/workflow.py` functions. The workflow is a directed graph that processes JIRA tickets through several stages:\n",
    "\n",
    "1. Extract task description from a JIRA ticket\n",
    "2. Generate SQL query based on the task\n",
    "3. Validate the SQL query\n",
    "4. Execute the query against a database\n",
    "5. Validate the query results\n",
    "6. Generate business insights from the results\n",
    "7. Update the JIRA ticket with the insights\n",
    "\n",
    "The system includes automatic retry logic for error handling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import logging\n",
    "from pathlib import Path\n",
    "\n",
    "# Add the project root to Python path\n",
    "project_root = Path().absolute().parent\n",
    "sys.path.append(str(project_root))\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "print(f\"Project root: {project_root}\")\n",
    "print(f\"Current working directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required components\n",
    "from src.agent.agent import DataAnalysisAgent\n",
    "from src.agent.workflow import create_workflow\n",
    "from src.clients.db_client import DatabaseClient\n",
    "from src.clients.jira_client import JiraClient\n",
    "from src.tools.sql_tool import SQLTool\n",
    "from src.tools.validator_tool import ValidatorTool\n",
    "from src.tools.insight_tool import InsightTool\n",
    "from src.models.schemas import JiraTicket, AgentState\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Initialize Components\n",
    "\n",
    "First, we need to initialize all the components that will be used in the workflow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the agent with configuration\n",
    "agent = DataAnalysisAgent(config_path=str(project_root / \"config\" / \"config.yaml\"))\n",
    "\n",
    "# Initialize database client\n",
    "DB_PATH = os.path.expanduser(\"../data/porsche_analytics.db\")\n",
    "sqlite_connection_string = f\"sqlite:///{DB_PATH}\"\n",
    "db_client = DatabaseClient(sqlite_connection_string)\n",
    "\n",
    "# Initialize JIRA client\n",
    "JIRA_BASE_URL = os.environ.get('JIRA_BASE_URL')\n",
    "JIRA_USER_EMAIL = os.environ.get('JIRA_USER_EMAIL')\n",
    "JIRA_API_TOKEN = os.environ.get('JIRA_API_TOKEN')\n",
    "jira_client = JiraClient(base_url=JIRA_BASE_URL, email=JIRA_USER_EMAIL, api_token=JIRA_API_TOKEN)\n",
    "\n",
    "# Initialize tools\n",
    "sql_tool = SQLTool(llm=agent.llm)\n",
    "validator_tool = ValidatorTool(llm=agent.llm, schema_dict=agent.schema)\n",
    "insight_tool = InsightTool(llm=agent.llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define Workflow Functions\n",
    "\n",
    "Now we need to define the functions that will be passed to `create_workflow()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the individual functions for each workflow step\n",
    "def generate_sql_function(task_description):\n",
    "    \"\"\"Generate SQL query from task description\"\"\"\n",
    "    return sql_tool.generate_query(task_description=task_description, schema_dict=agent.schema)\n",
    "\n",
    "def validate_sql_function(sql_query, task_description):\n",
    "    \"\"\"Validate SQL query\"\"\"\n",
    "    return validator_tool.validate_sql(sql_query=sql_query.query, task_description=task_description)\n",
    "\n",
    "def execute_query_function(query):\n",
    "    \"\"\"Execute SQL query against the database\"\"\"\n",
    "    return db_client.execute_query(query)\n",
    "\n",
    "def validate_results_function(query_result, task_description):\n",
    "    \"\"\"Validate query results\"\"\"\n",
    "    # Simple validation - check if we have data\n",
    "    is_valid = query_result.row_count > 0\n",
    "    errors = [] if is_valid else [\"Query returned no results\"]\n",
    "    return validator_tool.create_validation_result(is_valid=is_valid, errors=errors)\n",
    "\n",
    "def generate_insights_function(task_description, query_result):\n",
    "    \"\"\"Generate business insights from query results\"\"\"\n",
    "    return insight_tool.generate_insights(task_description=task_description, query_result=query_result)\n",
    "\n",
    "def update_jira_function(ticket_id, business_insight, failed=False):\n",
    "    \"\"\"Update JIRA ticket with insights\"\"\"\n",
    "    status = \"Failed\" if failed else \"Completed\"\n",
    "    comment = f\"**Analysis {status}**\\n\\n\"\n",
    "    \n",
    "    comment += f\"**Summary:** {business_insight.summary}\\n\\n\"\n",
    "    comment += \"**Key Points:**\\n\"\n",
    "    for point in business_insight.key_points:\n",
    "        comment += f\"- {point}\\n\"\n",
    "    \n",
    "    # In a real implementation, use jira_client to update the ticket\n",
    "    print(f\"Would update ticket {ticket_id} with comment:\\n{comment}\")\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create the Workflow\n",
    "\n",
    "Now we create the workflow by passing our functions to `create_workflow()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the workflow\n",
    "workflow = create_workflow(\n",
    "    generate_sql_fn=generate_sql_function,\n",
    "    validate_sql_fn=validate_sql_function,\n",
    "    execute_query_fn=execute_query_function,\n",
    "    validate_results_fn=validate_results_function,\n",
    "    generate_insights_fn=generate_insights_function,\n",
    "    update_jira_fn=update_jira_function,\n",
    "    max_retries=3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Run the Workflow with a Sample JIRA Ticket\n",
    "\n",
    "Let's create a sample JIRA ticket and run it through the workflow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sample JIRA ticket\n",
    "sample_ticket = JiraTicket(\n",
    "    ticket_id=\"KAN-8\",\n",
    "    summary=\"Car Models Analysis\",\n",
    "    description=\"How many unique car models do we have per car category? Sort the results in descending order!\",\n",
    "    created_at=\"2025-07-02T14:00:00\",\n",
    "    status=\"Open\"\n",
    ")\n",
    "\n",
    "# Initialize the agent state with the ticket\n",
    "initial_state = AgentState(\n",
    "    ticket=sample_ticket,\n",
    "    task_description=None,\n",
    "    sql_query=None,\n",
    "    validation_result=None,\n",
    "    query_result=None,\n",
    "    business_insight=None,\n",
    "    retry_count=0,\n",
    "    error_message=None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Execute the Workflow\n",
    "\n",
    "Now let's execute the workflow and trace the execution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the workflow with our initial state\n",
    "for event in workflow.stream(initial_state):\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    step_name = event[\"step\"]\n",
    "    state = event[\"state\"]\n",
    "    \n",
    "    # Print current step and key state information\n",
    "    print(f\"Step: {step_name}\")\n",
    "    \n",
    "    # Print relevant state information based on the step\n",
    "    if step_name == \"extract_task\" and state.task_description:\n",
    "        print(f\"Extracted task: {state.task_description}\")\n",
    "    \n",
    "    elif step_name == \"generate_sql\" and state.sql_query:\n",
    "        print(f\"Generated SQL: {state.sql_query.query}\")\n",
    "    \n",
    "    elif step_name == \"validate_sql\" and state.validation_result:\n",
    "        print(f\"SQL validation: {state.validation_result.is_valid}\")\n",
    "        if not state.validation_result.is_valid:\n",
    "            print(f\"Validation errors: {state.validation_result.errors}\")\n",
    "    \n",
    "    elif step_name == \"execute_query\" and state.query_result:\n",
    "        print(f\"Query executed with {state.query_result.row_count} rows returned\")\n",
    "    \n",
    "    elif step_name == \"validate_results\" and state.validation_result:\n",
    "        print(f\"Results validation: {state.validation_result.is_valid}\")\n",
    "    \n",
    "    elif step_name == \"generate_insights\" and state.business_insight:\n",
    "        print(f\"Generated insights summary: {state.business_insight.summary[:100]}...\")\n",
    "    \n",
    "    elif step_name == \"update_jira\":\n",
    "        print(f\"JIRA ticket {state.ticket.ticket_id} updated\")\n",
    "    \n",
    "    elif step_name == \"increment_retry\":\n",
    "        print(f\"Retry count incremented to {state.retry_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Workflow Visualization\n",
    "\n",
    "To better understand the workflow, let's visualize it (if graphviz is installed):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from IPython.display import display, Image\n",
    "    from langgraph.graph import get_graph_representation\n",
    "    import graphviz\n",
    "    \n",
    "    # Get the graph representation\n",
    "    graph_representation = get_graph_representation(workflow)\n",
    "    \n",
    "    # Create a Graphviz object\n",
    "    dot = graphviz.Digraph(comment='Data Analysis Workflow')\n",
    "    \n",
    "    # Add nodes\n",
    "    for node in graph_representation[\"nodes\"]:\n",
    "        dot.node(node, node)\n",
    "    \n",
    "    # Add edges\n",
    "    for edge in graph_representation[\"edges\"]:\n",
    "        dot.edge(edge[\"source\"], edge[\"target\"], label=edge.get(\"condition\", \"\"))\n",
    "    \n",
    "    # Render the graph\n",
    "    dot.render('workflow_graph', format='png', cleanup=True)\n",
    "    display(Image('workflow_graph.png'))\n",
    "except Exception as e:\n",
    "    print(f\"Could not generate workflow visualization: {e}\")\n",
    "    print(\"\\nWorkflow structure:\")\n",
    "    print(\"- Start with extract_task\")\n",
    "    print(\"- Move to generate_sql\")\n",
    "    print(\"- Validate SQL (branch based on validation result)\")\n",
    "    print(\"- If valid, execute query; otherwise retry or fail\")\n",
    "    print(\"- Validate results (branch based on validation)\")\n",
    "    print(\"- If valid, generate insights; otherwise retry or fail\")\n",
    "    print(\"- Update JIRA ticket\")\n",
    "    print(\"- End workflow\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook demonstrates how the `workflow.py` system works. Key points:\n",
    "\n",
    "1. The workflow is a directed graph built with LangGraph's `StateGraph`\n",
    "2. It processes JIRA tickets through a series of steps (SQL generation, validation, execution, etc.)\n",
    "3. It includes conditional branching for error handling and retries\n",
    "4. The state is maintained throughout the process in an `AgentState` object\n",
    "5. Each function in the workflow takes a state object and returns an updated state object\n",
    "6. The `create_workflow()` function wires everything together based on the function implementations provided\n",
    "\n",
    "This orchestration system allows for a robust and modular approach to automated data analysis tasks from JIRA tickets."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-analyzer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}